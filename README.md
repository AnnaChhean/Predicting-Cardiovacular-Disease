## Project Description
### In this project, I cleaned and reblanced data to get data ready for predictive modeling. Data is split into two different sizes (small and large) for training and testing. Model applied: Dicision Trees, Random Forest, Baggign and Boosting. Each model performance is evaulated and results are summarized as follow:
### •	For General Accuracy: Random Forest or Bagging
### •	For Minimizing False Negatives (High Recall): Boosting or Bagging
### •	For Balancing Both: Bagging is the best compromise
### Given that misclassifying at-risk patients (false negatives) is costly, Boosting is a strong candidate because it improves recall while maintaining reasonable accuracy. However, if we want a stable and high-performing model overall, Bagging is the better choice since it offers both high recall and accuracy.
